# Machine Learning && LLM Note

## LLM Note
[網址](https://www.youtube.com/watch?v=KjB8TwUJeag)
1. 預訓練
相當於嬰兒成長到國中生的階段，這過程我們需要學習大量的語言邏輯知識
對於大語言模型來說，這個過程是學習大量的語言與料
但也只是達到了浦泉句子的能Machine Learning && LLM Note
LLM Note

參考：Titanic Kaggle 競賽

1. 預訓練（Pre-training）

可以把它想成「嬰兒 → 國中生」的學習過程。

在這個階段，模型會接觸大量文字資料，學習語言的規律（例如詞語搭配、句子結構、知識片段）。

但這時候模型只是會「拼湊出合理的句子」，並不一定能正確理解問題或給出符合人類需求的答案。

例如你問它：「艾菲爾鐵塔在哪裡？」

模型可能只憑「鐵塔」「城市」「民族」這些字的關聯，胡亂組合成一句話，而不一定會正確回答「在法國巴黎」。

➡️ 這個階段的重點：
模型學會「語言形式」和「統計關聯」，但還沒有被調教到能準確理解人類意力
例如你問他說艾菲爾鐵塔在哪裡？他不可能回你法國。
而是會根據你有的餘料拼湊成一個句子回答東方民族在哪個城市
橫藍這並不是一個好的回答
因此我們需要讓他可以理解我們人類的意思以及更好的回答，所以需要
S F T監督微調